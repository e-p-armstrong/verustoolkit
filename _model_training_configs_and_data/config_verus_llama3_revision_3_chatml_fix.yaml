# This is an axolotl config that allows creation of a model knowledgeable about Verus.
# Rent a GPU with a compute provider like Vast.ai or Runpod
# (Make sure it is using the axolotl docker image --- winglian/axolotl:main-latest)
# Copy this file over to the rented instance, in the /workspace/axolotl directory
# If running on a single-GPU setup, you must run:
# conda install -c conda-forge mpi4py mpich
# Then run this command from the /workspace/axolotl directory:
# accelerate launch --use_deepspeed -m axolotl.cli.train config_verus_llama3_revision_3_chatml_fix.yaml

# Next up, try not sample packing to handle unexpected pos?



# (to copy files over to a rented GPU instance, you'll have to use SSH to Secure CoPy files over from your machine to the rented one. This is what such a command might look like, adapt it to your needs)
# scp -P 40001 -r lima-sharegpt.jsonl simplified_data_rag.jsonl simplified_data_no_rag.jsonl pretraining.json config_verus_both.yaml root@173.231.62.170:/workspace/axolotl/


base_model: meta-llama/Meta-Llama-3-8B
model_type: LlamaForCausalLM
tokenizer_type: AutoTokenizer

load_in_8bit: false
load_in_4bit: false
strict: false

datasets:
  - path: json
    data_files: pretraining_vision.json
    ds_type: json
    type: completion
  - path: json
    data_files: simplified_data_rag_VISION.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_VISION.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_rag_OPENENDED_VISION.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_OPENENDED_VISION.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: evol_split_1.json
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: unnatural_split_1.json
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: pretraining_medium.json
    ds_type: json
    type: completion
  - path: json
    data_files: simplified_data_rag_MEDIUM.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_MEDIUM.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_rag_OPENENDED_MEDIUM.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_OPENENDED_MEDIUM.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: orca_split_1.json
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: orca_split_2.json
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: pretraining_wiki.json
    ds_type: json
    type: completion
  - path: json
    data_files: simplified_data_rag_WIKI.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_WIKI.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_rag_OPENENDED_WIKI.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_OPENENDED_WIKI.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: cot_alpaca_split_1.json
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: unnatural_split_2.json
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: pretraining_api.json
    ds_type: json
    type: completion
  - path: json
    data_files: simplified_data_rag_API.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_API.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_rag_OPENENDED_API.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_OPENENDED_API.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: cot_alpaca_split_2.json
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: unnatural_split_2.json
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: pretraining_docs.json
    ds_type: json
    type: completion
  - path: json
    data_files: simplified_data_rag_DOCS.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_DOCS.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_rag_OPENENDED_DOCS.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml
  - path: json
    data_files: simplified_data_no_rag_OPENENDED_DOCS.jsonl
    ds_type: json
    type: sharegpt
    conversation: chatml

dataset_prepared_path: last_run_prepared
output_dir: ./verus-out-chatml-fix

sequence_len: 4500
sample_packing: true
pad_to_sequence_len: true

wandb_project: verus-llama-revision-3
wandb_entity:
wandb_watch:
wandb_run_id:
wandb_log_model:

gradient_accumulation_steps: 2
micro_batch_size: 3
num_epochs: 6
optimizer: paged_adamw_8bit
lr_scheduler: cosine
learning_rate: 1e-5
noisy_embedding_alpha: 0 # no noisy embedding to ensure maximal memorization 

train_on_inputs: false
group_by_length: false
bf16: true
fp16: false
tf32: false

gradient_checkpointing: unsloth
early_stopping_patience:
resume_from_checkpoint: 
logging_steps: 1
xformers_attention:
flash_attention: true

warmup_steps: 100
auto_resume_from_checkpoints: false
eval_steps: 10
saves_per_epoch: 1
eval_sample_packing: false
save_total_limit: 4
debug:
deepspeed: deepspeed_configs/zero2.json
chat_template: chatml
special_tokens:
  eos_token: "<|im_end|>"
  pad_token: "<|end_of_text|>"
tokens:
  - "<|im_start|>"
  - "<|im_end|>"