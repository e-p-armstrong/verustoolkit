[
    "How does Verus protect user privacy when using machine learning on human data?",
    "Verus ensures user privacy by only allowing machine learning algorithms to access data that users explicitly permit. Additionally, the default setting is for resulting information to be made public, unless those creating polls pay the Verus community a fee to keep the data private.",
    "A major Verus advantage over almost any other system in its use of Machine learning on\nhuman data is the innate privacy it provides to those whose data is used for learning, along\nwith the default that all resulting information be made public, unless those making polls pay\nthe Verus community a going rate to keep the data for themselves. In today\u2019s society, the\ngoal of most machine learning systems is to match consumers with products they are likely to\nbuy and/or manipulate them into an actual purchase, thus generating revenue. This creates\na situation that can create unintended negative consequences when algorithms disregard any\npositive or negative effects its predictive abilities may have on society [23]. For example, if\nthe algorithm recognizes that people with depressive episodes are more likely to gamble, and\nthus buy airline tickets to gambling-oriented locations, such as Las Vegas, it will advertise\nthose airline tickets to those people. In the Verus system, machine learning algorithms will\nbe able to learn from human beings, while being limited to accessing only the data users\npermit, and at the same time, being unable to easily target any specific individual.3.6Verus Mobile Polls18",
    "./raw_text_input_vision_paper/VerusVisionPaper"
]